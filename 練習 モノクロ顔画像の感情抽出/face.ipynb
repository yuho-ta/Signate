{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13_hbd7KgWar0i7Ii0UNTCANW3_8W6vhg","authorship_tag":"ABX9TyMcUmxIEYWTiNu87uEBZXZ2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"6BKXcWrM6haJ","executionInfo":{"status":"ok","timestamp":1708131543934,"user_tz":-540,"elapsed":231,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}}},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train_master.tsv\",sep=\"\\t\")"]},{"cell_type":"code","source":["import os\n","import zipfile\n","import torch\n","from torchvision import datasets, models, transforms\n","from PIL import Image\n","import re"],"metadata":{"id":"CMGWtAmdP8Sc","executionInfo":{"status":"ok","timestamp":1708131544166,"user_tz":-540,"elapsed":3,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# transformsの定義\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.RandomHorizontalFlip(p=0.5),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","    ]),\n","}\n","image_datasets = {\n","    'train': datasets.ImageFolder('/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /train',  data_transforms['train']),\n","    'val': datasets.ImageFolder('/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /val', data_transforms['val'])\n","}\n","\n","# dataloaders 作成\n","image_dataloaders = {\n","    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=20, shuffle=True, num_workers=0, drop_last=True),\n","    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=20, shuffle=False, num_workers=0, drop_last=True),\n","}\n","import torch.nn as nn\n","import torch.optim as optim\n","device = \"cpu\"\n","TARGET_NUM = 4\n","\n","# モデル作成関数の定義\n","def get_model(target_num,isPretrained=False):\n","    \"\"\"for get model\"\"\"\n","\n","    model_ft = models.resnet18(pretrained=isPretrained)\n","    model_ft.fc = nn.Linear(512, target_num)\n","    model_ft = model_ft.to(device)\n","    return model_ft\n","\n","# モデルのインスタンス作成\n","model = get_model(TARGET_NUM,isPretrained=False)\n","# 最適化関数定義\n","optimizer = optim.SGD(model.parameters(),lr=0.001, momentum=0.9)\n","\n","# loss関数定義\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"Djx0Wq-xUtOa","executionInfo":{"status":"ok","timestamp":1708131544504,"user_tz":-540,"elapsed":340,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a883e3f-cb0a-4cf8-ddff-d051325517e3"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image, ImageFilter"],"metadata":{"id":"65HoOQaxklkf","executionInfo":{"status":"ok","timestamp":1708131544504,"user_tz":-540,"elapsed":1,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import re\n","TARGET_NUM = 4\n","test = pd.DataFrame(data= os.listdir('/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/test'))\n","test = test.rename(columns={0: 'filename'})\n","test['filename'] = sorted(test['filename'], key=lambda x: int(re.search(r'(\\d+)', x).group()))\n","# targetカラム作成\n","test['target'] = 0\n","\n","# 事前学習済みResNet18モデルのインスタンス作成\n","pretrained_model = get_model(target_num=TARGET_NUM)\n","pretrained_model.load_state_dict(torch.load('/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/original_model_0.pth', map_location=lambda storage, loc: storage), strict=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvdBgdv4oJbB","executionInfo":{"status":"ok","timestamp":1708131645221,"user_tz":-540,"elapsed":493,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}},"outputId":"21a421d7-244b-42f4-b206-05b0b1c03862"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# 推論用のtransforms作成\n","test_transforms = transforms.Compose([\n","               transforms.Resize(256),\n","               transforms.ToTensor(),\n","               transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n","\n","])\n","\n","# dataset作成\n","class Test_Datasets(Dataset):\n","\n","    def __init__(self, data_transform):\n","\n","        self.df = test\n","        self.data_transform = test_transforms\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","\n","        file = self.df['filename'][index]\n","        image = Image.open('/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/test/'+ file)\n","        image = image.convert('RGB')\n","        image = self.data_transform(image)\n","        return image,file\n"],"metadata":{"id":"EnthRkEKoZxy","executionInfo":{"status":"ok","timestamp":1708132377344,"user_tz":-540,"elapsed":266,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# datasetのインスタンス作成\n","test_dataset = Test_Datasets(data_transform=test_transforms)\n","\n","# dataloader作成\n","test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                                batch_size=1,\n","                                                shuffle=False,\n","                                                num_workers=0 ,\n","                                                drop_last=True )"],"metadata":{"id":"24hVKTSIod6k","executionInfo":{"status":"ok","timestamp":1708132377599,"user_tz":-540,"elapsed":3,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["pred = []  # 予測を保存するリストを初期化\n","for i,(inputs, labels) in enumerate(test_dataloader):\n","    inputs = inputs.to(device)\n","    # 学習済みモデルを推論モードに設定\n","    pretrained_model.eval()\n","    # 学習済みモデルにデータをインプットし、推論をさせる\n","    outputs = pretrained_model(inputs)\n","    print(outputs)\n","    _, preds_idx = torch.max(outputs,1)\n","\n","    # インデックスを0〜3の値に変換\n","    preds = preds_idx.tolist()\n","\n","    # 事前に用意したリストに推論結果を格納\n","    pred.extend(preds)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKD11kl4opFz","executionInfo":{"status":"ok","timestamp":1708132427213,"user_tz":-540,"elapsed":49616,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}},"outputId":"26fa43a1-8d89-4d41-edb3-971256a3b6f8"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.2056,  0.3218, -0.0603,  0.2637]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3025,  0.2696, -0.1294,  0.2187]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2150,  0.2716, -0.1861,  0.2621]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2874,  0.2505, -0.1264,  0.2211]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3007,  0.1864, -0.0985,  0.1434]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2548,  0.2285, -0.0977,  0.2637]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2922,  0.3051, -0.1076,  0.2439]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3203,  0.2199, -0.1260,  0.2302]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2555,  0.1965, -0.0528,  0.3176]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2680,  0.2129, -0.0825,  0.2462]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3061,  0.2502, -0.0110,  0.2681]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3285,  0.3070, -0.1360,  0.3270]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3064,  0.2204, -0.1257,  0.2395]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3002,  0.2789, -0.1391,  0.3834]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2436,  0.2701, -0.1599,  0.2755]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2968,  0.2623, -0.1103,  0.2476]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2606,  0.2536, -0.1002,  0.0820]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2816,  0.2458, -0.0630,  0.1748]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2994,  0.2121, -0.0766,  0.1660]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2966,  0.2219, -0.1533,  0.1623]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2309,  0.2329, -0.0209,  0.2632]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2938,  0.1535, -0.1265,  0.2381]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2960,  0.2722, -0.0375,  0.2490]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2913,  0.2645, -0.0894,  0.3763]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2776,  0.2577, -0.1040,  0.2937]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2812,  0.2117, -0.1819,  0.3654]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2215,  0.2985, -0.0408,  0.3444]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2876,  0.2112, -0.0900,  0.1530]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3008,  0.2019, -0.0819,  0.0965]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2747,  0.2446, -0.0780,  0.1476]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2405,  0.2075, -0.0791,  0.2342]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3470,  0.2339, -0.1726,  0.3260]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3060,  0.1994, -0.0993,  0.0991]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3623,  0.2627, -0.1005,  0.3178]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2521,  0.2356, -0.1077,  0.3242]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2755,  0.2908, -0.1372,  0.2129]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2413,  0.2431, -0.1518,  0.2785]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2626,  0.2119, -0.1921,  0.2768]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2658,  0.2485, -0.1834,  0.3287]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2956,  0.2202, -0.1193,  0.2815]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3505,  0.2320, -0.0869,  0.1553]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2769,  0.2272, -0.1197,  0.2365]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2901,  0.2005, -0.0598,  0.2395]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2860,  0.2866, -0.0471,  0.2030]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2517,  0.2384, -0.1608,  0.3570]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2961,  0.2453, -0.0674,  0.2407]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2667,  0.3158, -0.1015,  0.2987]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2684,  0.2006, -0.0372,  0.3156]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2706,  0.2400, -0.0954,  0.1310]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2770,  0.2250, -0.1267,  0.1560]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2288,  0.2459, -0.0041,  0.3157]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2879,  0.2554, -0.0651,  0.1622]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2309,  0.3110, -0.1162,  0.3193]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3212,  0.2524, -0.1358,  0.3522]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2710,  0.2776, -0.0240,  0.2360]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2356,  0.1828, -0.0638,  0.3266]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2872,  0.1862, -0.0712,  0.1424]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2222,  0.2177, -0.1040,  0.3281]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2935,  0.2543, -0.1417,  0.2086]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2888,  0.2340, -0.1224,  0.2422]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3310,  0.2504, -0.2800,  0.4135]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2853,  0.2174, -0.0826,  0.1671]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2317,  0.2254, -0.0617,  0.2880]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2980,  0.1832, -0.1092,  0.0483]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2791,  0.2804, -0.0250,  0.3739]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2440,  0.2674, -0.1401,  0.2986]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2296,  0.2782, -0.1349,  0.3159]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3029,  0.2550, -0.1444,  0.3641]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2399,  0.2399, -0.0859,  0.1915]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3117,  0.2977, -0.1665,  0.3778]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2959,  0.2408, -0.1051,  0.2242]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3212,  0.2266, -0.0181,  0.1928]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3276,  0.2062, -0.2647,  0.3889]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3231,  0.2292, -0.1985,  0.3083]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2782,  0.2324, -0.1169,  0.2556]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2742,  0.2475, -0.1007,  0.2566]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3133,  0.3023, -0.1514,  0.3806]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2877,  0.2442, -0.1528,  0.3615]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3046,  0.2455, -0.1066,  0.2317]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2807,  0.2793, -0.1030,  0.2007]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2994,  0.1930, -0.1050,  0.2024]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2837,  0.2370, -0.0478,  0.0664]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2795,  0.2061, -0.0990,  0.3430]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2795,  0.2718, -0.0872,  0.2775]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3288,  0.2245, -0.1320,  0.1869]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2794,  0.3185, -0.1323,  0.3734]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2873,  0.2269, -0.1400,  0.3187]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2343,  0.2520, -0.1219,  0.2352]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2922,  0.2191, -0.0586,  0.2540]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2859,  0.2359, -0.1025,  0.2402]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2678,  0.1977, -0.0872,  0.1726]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3049,  0.1955, -0.0398,  0.0477]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2316,  0.2818, -0.1540,  0.3857]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2909,  0.2327, -0.0747,  0.2184]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3092,  0.2539, -0.0453,  0.3477]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2884,  0.2269, -0.0080,  0.2494]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2429,  0.3122, -0.0915,  0.2941]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2892,  0.2645, -0.0532,  0.1519]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2226,  0.2099, -0.0866,  0.2471]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2745,  0.2092, -0.1377,  0.2579]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3030,  0.2106, -0.1886,  0.3332]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2636,  0.2573, -0.0229,  0.3065]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2413,  0.2859, -0.1247,  0.3315]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2938,  0.2027, -0.1183,  0.3088]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2840,  0.2203, -0.1038,  0.1506]], grad_fn=<AddmmBackward0>)\n","tensor([[0.2994, 0.2027, 0.0077, 0.1935]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2284,  0.2472, -0.1386,  0.3695]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2107,  0.2700, -0.0505,  0.3532]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2755,  0.2108, -0.1509,  0.3177]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3217,  0.2423, -0.1103,  0.3083]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2907,  0.2373, -0.0146,  0.2806]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2678,  0.2420, -0.0668,  0.1594]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3150,  0.1864, -0.0853,  0.2381]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2228,  0.2904, -0.1231,  0.2898]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2804,  0.2360, -0.0961,  0.2386]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2544,  0.1858, -0.1265,  0.2132]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2734,  0.2180, -0.1612,  0.3529]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2953,  0.1880, -0.1512,  0.3232]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2580,  0.2131, -0.0979,  0.3120]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2204,  0.2771, -0.1288,  0.3963]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3515,  0.2343, -0.1268,  0.3356]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3056,  0.2251, -0.1281,  0.2543]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3098,  0.2022, -0.0718,  0.2309]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2653,  0.1870, -0.0832,  0.1948]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3176,  0.1843, -0.1418,  0.2393]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2847,  0.2666, -0.0512,  0.3416]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2840,  0.2605, -0.0795,  0.1691]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2869,  0.3059, -0.1031,  0.1986]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2889,  0.2219, -0.1219,  0.1256]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2655,  0.2558, -0.1061,  0.1537]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2446,  0.1854, -0.1128,  0.1961]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2963,  0.2123, -0.1376,  0.2895]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2368,  0.2880, -0.1144,  0.3765]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3258,  0.2370, -0.1340,  0.3040]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2629,  0.2412, -0.0661,  0.2017]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2715,  0.2508, -0.0788,  0.2273]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2941,  0.2367, -0.1437,  0.1941]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2483,  0.2050, -0.1018,  0.3489]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2976,  0.1469, -0.0847,  0.2447]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2841,  0.1786, -0.1067,  0.2779]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3402,  0.2047, -0.0796,  0.1367]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2873,  0.2282, -0.0592,  0.2666]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2567,  0.2318, -0.1320,  0.2147]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2490,  0.2856, -0.1058,  0.2408]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2881,  0.2211, -0.1050,  0.1456]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2318,  0.2812, -0.0667,  0.3257]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3279,  0.2570, -0.1913,  0.3318]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2983,  0.2576, -0.0708,  0.2170]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3193,  0.2106, -0.0937,  0.3470]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2910,  0.2125, -0.1460,  0.2643]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2446,  0.2710, -0.1033,  0.2816]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3430,  0.2671, -0.1142,  0.1706]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2571,  0.2163, -0.1247,  0.2688]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2974,  0.2265, -0.0956,  0.1489]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3080,  0.2558, -0.0864,  0.1381]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2767,  0.2286, -0.0503,  0.1356]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2571,  0.2554, -0.0924,  0.3561]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3133,  0.2559, -0.1247,  0.0704]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2631,  0.2385, -0.1154,  0.2153]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2927,  0.2572, -0.1277,  0.1335]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3494,  0.2780, -0.1187,  0.3877]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2882,  0.2421, -0.0321,  0.2905]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2743,  0.2656, -0.1215,  0.2342]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3320,  0.1801, -0.1261,  0.3470]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2818,  0.2172, -0.0920,  0.2634]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2994,  0.1929, -0.1257,  0.3047]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3258,  0.2685, -0.0235,  0.3362]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3055,  0.2471, -0.0184,  0.1991]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3061,  0.3218, -0.0201,  0.3581]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2714,  0.2296, -0.0576,  0.3452]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2600,  0.2538, -0.1006,  0.1599]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3279,  0.2734, -0.1172,  0.2588]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2577,  0.2223, -0.0488,  0.3257]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2704,  0.2449, -0.1137,  0.3447]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2821,  0.2216, -0.0658,  0.2443]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3121,  0.2550, -0.1028,  0.1951]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2203,  0.3032, -0.1118,  0.2520]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2802,  0.2314, -0.0975,  0.2977]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2934,  0.2931, -0.0454,  0.3647]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2641,  0.2210, -0.1059,  0.3270]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2828,  0.2385, -0.1571,  0.2582]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2703,  0.2284, -0.0902,  0.3236]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3051,  0.2700, -0.0909,  0.2156]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2596,  0.1674, -0.1355,  0.3385]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2669,  0.2316, -0.0536,  0.1586]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2762,  0.2548, -0.1318,  0.1793]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2916,  0.2730, -0.1625,  0.1912]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3002,  0.2851, -0.0970,  0.3344]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2786,  0.2239, -0.1099,  0.0813]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2474,  0.2636, -0.1185,  0.2448]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2474,  0.1952, -0.0906,  0.2721]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2388,  0.1913, -0.0466,  0.3299]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3219,  0.1929, -0.1144,  0.2116]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2900,  0.2001, -0.0914,  0.0889]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2999,  0.2235, -0.0550,  0.2397]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2925,  0.2441, -0.1552,  0.4007]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3168,  0.1789, -0.1075,  0.1939]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3069,  0.2051, -0.1717,  0.3152]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2554,  0.2197, -0.0147,  0.1284]], grad_fn=<AddmmBackward0>)\n","tensor([[0.2750, 0.1890, 0.0056, 0.1820]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2880,  0.2164, -0.0919,  0.1074]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2846,  0.2423, -0.1645,  0.2626]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2857,  0.2899, -0.0583,  0.3426]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2881,  0.2820, -0.1334,  0.3815]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2564,  0.1855, -0.1008,  0.3258]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2809,  0.2685, -0.1560,  0.3842]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3245,  0.2366, -0.0771,  0.1392]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2409,  0.2490, -0.1769,  0.3756]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3111,  0.2289, -0.0631,  0.1201]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2965,  0.2571, -0.1456,  0.1550]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3244,  0.2553, -0.1387,  0.3553]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2844,  0.2738, -0.1066,  0.1136]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3035,  0.2266, -0.1356,  0.0429]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2580,  0.2489, -0.0372,  0.3226]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2370,  0.2853, -0.1201,  0.3566]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2976,  0.2594, -0.1391,  0.3560]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2333,  0.2788, -0.1250,  0.2614]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2426,  0.2407, -0.0728,  0.1770]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2904,  0.2656, -0.0856,  0.4072]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2716,  0.2152, -0.0100,  0.1344]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3073,  0.2441, -0.1325,  0.1007]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2831,  0.3151, -0.1051,  0.3024]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3105,  0.2518, -0.1242,  0.2035]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2370,  0.2156, -0.1186,  0.2813]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2933,  0.1639, -0.0824,  0.2915]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2937,  0.2065, -0.1335,  0.2626]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2816,  0.2476, -0.1321,  0.2518]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2975,  0.2902, -0.1187,  0.2596]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2681,  0.2040, -0.0841,  0.2062]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3226,  0.2216, -0.1403,  0.1754]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2866,  0.2199, -0.0820,  0.0831]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2544,  0.2541, -0.2032,  0.2810]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2570,  0.3168, -0.0060,  0.3533]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2832,  0.1933, -0.0175,  0.1277]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3298,  0.2767, -0.1701,  0.3325]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3236,  0.2251, -0.0636,  0.2975]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2687,  0.2396, -0.0919,  0.1283]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3101,  0.2207, -0.0960,  0.1251]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3141,  0.2336, -0.0807,  0.1826]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2436,  0.2882, -0.0253,  0.3263]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2853,  0.2539, -0.1038,  0.1094]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2584,  0.2592, -0.1046,  0.2137]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3360,  0.2609, -0.1071,  0.3307]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3032,  0.2992, -0.1011,  0.2921]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3080,  0.2295, -0.0862,  0.1043]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2870,  0.2146, -0.1834,  0.2994]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2728,  0.2100, -0.1389,  0.2562]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2877,  0.2580, -0.1567,  0.2046]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3025,  0.2144, -0.1293,  0.1469]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3209,  0.2507, -0.1221,  0.1493]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3144,  0.2326, -0.1035,  0.3284]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2586,  0.2300, -0.0923,  0.2203]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2190,  0.2412, -0.1521,  0.3347]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3212,  0.2129, -0.1714,  0.2210]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2754,  0.2734, -0.1370,  0.3468]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3059,  0.2291, -0.1166,  0.1278]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3137,  0.2412, -0.2800,  0.4143]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2977,  0.2889, -0.1424,  0.3743]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2987,  0.1882, -0.1162,  0.1984]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3260,  0.2194, -0.1217,  0.2623]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2639,  0.2473, -0.0167,  0.2369]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2863,  0.2358, -0.0453,  0.2936]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2601,  0.1955, -0.0869,  0.2486]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2559,  0.2824, -0.0306,  0.3270]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2230,  0.2854, -0.1416,  0.3799]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3036,  0.2363, -0.0733,  0.2245]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2878,  0.2171, -0.0721,  0.3157]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2544,  0.2565, -0.0275,  0.2717]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2586,  0.2377, -0.0843,  0.1807]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2136,  0.1788, -0.0806,  0.1931]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2812,  0.2734, -0.0168,  0.2360]], grad_fn=<AddmmBackward0>)\n","tensor([[0.3086, 0.2479, 0.0089, 0.2666]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3609,  0.3075, -0.1361,  0.3908]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2564,  0.3066, -0.1272,  0.3992]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2843,  0.1603, -0.1056,  0.1647]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2656,  0.2780, -0.1249,  0.2835]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2577,  0.3075, -0.0241,  0.2217]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3304,  0.2502, -0.1522,  0.3896]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2910,  0.2127, -0.1023,  0.1042]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2617,  0.2601, -0.0407,  0.2995]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2894,  0.2467, -0.0740,  0.2198]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2825,  0.2235, -0.0988,  0.2848]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2930,  0.2967, -0.1381,  0.3761]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2668,  0.2275, -0.0764,  0.2195]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2712,  0.2395, -0.1023,  0.1559]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3036,  0.2242, -0.0112,  0.1849]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2754,  0.1974, -0.0712,  0.0900]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2844,  0.1909, -0.1278,  0.2534]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2521,  0.2066, -0.1213,  0.3531]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2277,  0.2525, -0.1448,  0.4503]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2835,  0.2017, -0.0815,  0.2438]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2364,  0.2545, -0.0839,  0.1967]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3013,  0.1826, -0.1053,  0.1267]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3038,  0.2451, -0.0962,  0.1650]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2637,  0.1513, -0.1599,  0.2991]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2816,  0.2007, -0.0797,  0.1951]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2706,  0.2263, -0.0726,  0.2362]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2404,  0.2532, -0.1116,  0.2481]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2962,  0.2380, -0.0569,  0.2715]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2815,  0.2314, -0.1398,  0.2699]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3423,  0.2539, -0.1395,  0.1722]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2670,  0.2018, -0.1137,  0.2270]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2488,  0.2551, -0.0894,  0.2154]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2739,  0.2653, -0.1411,  0.2112]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2527,  0.2363, -0.0666,  0.1179]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2884,  0.2419, -0.1468,  0.1981]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2760,  0.2180, -0.1063,  0.2301]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.3435,  0.2693, -0.1390,  0.1751]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2911,  0.2349, -0.0346,  0.2918]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2088,  0.2194, -0.1641,  0.3361]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2742,  0.1855, -0.0983,  0.1969]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.2753,  0.2797, -0.1428,  0.3373]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["ans = []\n","for i in pred:\n","    if i == 0:\n","        ans.append('angry')\n","    elif i == 1:\n","        ans.append('happy')\n","    elif i == 2:\n","        ans.append('neutral')\n","    else:\n","        ans.append('sad')\n","\n","test['target'] = ans\n","print(ans)\n","test.to_csv('/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/test.csv',  header=False, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GA-OM5_Gm_6s","executionInfo":{"status":"ok","timestamp":1708132427213,"user_tz":-540,"elapsed":11,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}},"outputId":"9d36db7e-0830-4b24-a82c-c6c1df90e394"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["['happy', 'angry', 'happy', 'angry', 'angry', 'sad', 'happy', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'angry', 'sad', 'sad', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'sad', 'happy', 'sad', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'happy', 'sad', 'angry', 'happy', 'sad', 'angry', 'angry', 'sad', 'angry', 'sad', 'sad', 'happy', 'sad', 'angry', 'sad', 'angry', 'angry', 'sad', 'angry', 'sad', 'angry', 'sad', 'sad', 'sad', 'sad', 'angry', 'sad', 'angry', 'angry', 'sad', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'angry', 'sad', 'sad', 'happy', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'sad', 'angry', 'happy', 'angry', 'sad', 'angry', 'sad', 'sad', 'sad', 'sad', 'angry', 'angry', 'sad', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'happy', 'angry', 'angry', 'sad', 'sad', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'happy', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'angry', 'happy', 'angry', 'sad', 'sad', 'angry', 'sad', 'angry', 'sad', 'angry', 'sad', 'angry', 'angry', 'angry', 'sad', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'sad', 'angry', 'sad', 'sad', 'angry', 'sad', 'sad', 'angry', 'angry', 'sad', 'sad', 'angry', 'angry', 'happy', 'sad', 'sad', 'sad', 'angry', 'sad', 'angry', 'sad', 'angry', 'angry', 'angry', 'sad', 'angry', 'happy', 'sad', 'sad', 'angry', 'angry', 'angry', 'sad', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'sad', 'sad', 'sad', 'angry', 'sad', 'angry', 'angry', 'sad', 'angry', 'angry', 'sad', 'sad', 'sad', 'happy', 'angry', 'sad', 'angry', 'angry', 'happy', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'happy', 'angry', 'angry', 'angry', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'sad', 'angry', 'sad', 'angry', 'sad', 'sad', 'angry', 'angry', 'angry', 'sad', 'angry', 'sad', 'sad', 'angry', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'sad', 'happy', 'sad', 'angry', 'sad', 'angry', 'sad', 'sad', 'angry', 'angry', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'happy', 'angry', 'angry', 'sad', 'angry', 'angry', 'happy', 'angry', 'angry', 'angry', 'angry', 'happy', 'angry', 'angry', 'angry', 'angry', 'angry', 'sad', 'sad', 'angry', 'sad']\n"]}]},{"cell_type":"code","source":["root_path='/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /val'\n","for id, expression in zip(df['id'], df['expression']):\n","      # 新しいフォルダーパスを生成\n","      new_folder_path = f\"{root_path}/{expression}/{id}\"\n","      # 旧フォルダーパスを生成\n","      old_folder_path = f\"{root_path}/{id}\"\n","      if int(re.findall(r'\\d+', id)[0]) > 250:\n","      # フォルダーを移動する\n","         os.replace(old_folder_path, new_folder_path)\n"],"metadata":{"id":"OlEYEu-jVtRL","executionInfo":{"status":"error","timestamp":1708132427622,"user_tz":-540,"elapsed":417,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}},"colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"e130cd53-44f7-40fa-b436-8697d01173d0"},"execution_count":45,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /val/train_0251.jpg' -> '/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /val/angry/train_0251.jpg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-d823f0b5bc3c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# フォルダーを移動する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m          \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /val/train_0251.jpg' -> '/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/train /val/angry/train_0251.jpg'"]}]},{"cell_type":"code","source":["\n","# モデル学習用関数\n","def train_model(model, criterion, optimizer, num_epochs=5,is_saved = False):\n","    best_acc = 0.0\n","\n","    # エポック数だけ下記工程の繰り返し\n","    for epoch in range(num_epochs):\n","\n","        for phase in ['train', 'val']:\n","            print('{}:フェイズ'.format(phase))\n","\n","            # 訓練フェイズと検証フェイズの切り替え\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # dataloadersからバッチサイズだけデータ取り出し、下記工程（1−5）の繰り返し\n","            for i,(inputs, labels) in enumerate(image_dataloaders[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # 1. optimizerの勾配初期化\n","                optimizer.zero_grad()\n","\n","                # 2.モデルに入力データをinputし、outputを取り出す\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                print(preds)\n","                # 3. outputと正解ラベルから、lossを算出\n","                loss = criterion(outputs, labels)\n","                print('   loaders:{}回目'.format(i+1)  ,'   loss:{}'.format(loss))\n","\n","                if phase == 'train':\n","                    # 4. 誤差逆伝播法により勾配の算出\n","                    loss.backward()\n","                    # 5. optimizerのパラメータ更新\n","                    optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            dataset_sizes = len(image_datasets[phase])\n","            epoch_loss = running_loss / dataset_sizes\n","            epoch_acc = running_corrects.double() / dataset_sizes\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # C. 今までのエポックでの精度よりも高い場合はモデルの保存\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                if(is_saved):\n","                    torch.save(model.state_dict(), '/content/drive/MyDrive/signate/練習 モノクロ顔画像の感情抽出/original_model_{}.pth'.format(epoch))\n","\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","train_model(model, criterion, optimizer, num_epochs=5,is_saved =True)"],"metadata":{"id":"WDdoH8SelPko","executionInfo":{"status":"aborted","timestamp":1708132427623,"user_tz":-540,"elapsed":2,"user":{"displayName":"田村優帆","userId":"00266925889065881776"}}},"execution_count":null,"outputs":[]}]}